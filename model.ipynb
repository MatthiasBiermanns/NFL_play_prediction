{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training for NFL play prediction\n",
    "\n",
    "---\n",
    " \n",
    "In this notebook, we train multiple regression and ANN models to predict the yards gained per football play. As a basis we use the preselected data created by the `preprocessing.py``.\n",
    "\n",
    "### Inline preprocessing steps:\n",
    "\n",
    "---\n",
    "\n",
    "As we use 5-fold cross-validation to protect the model against overfitting, we need a dynamic preprocessing appraoch. Therefore a pipeline provided by the `preprocessing.py`` will be used to process the training data of each fold. Further we use a nested cross validation to ensure the quality of our model using selected hyperparameters.\n",
    "\n",
    "\n",
    "### Contributors\n",
    "\n",
    "All contributors are only assigned to their primary task, the teams still interchanged know-how and worked on one anothers approaches.\n",
    "\n",
    "---\n",
    "\n",
    "##### Preprocessing Team\n",
    "\n",
    "- Tim Oliver Krause (1689074)\n",
    "- Jan Thilo Viktorin (1684159)\n",
    "- Joël Pflomm (1634591)\n",
    "\n",
    "##### Model Team\n",
    "\n",
    "- Franziska Köllschen (1981780)\n",
    "- Steffen Hüls (1979863)\n",
    "- Matthias Biermanns (1980701)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Foundations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "\n",
    "# import for preprocessing\n",
    "import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# import used models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# imports for evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV, ParameterGrid\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static variables\n",
    "FILE_LIST = [f'./Data/play_by_play_{year}.csv' for year in range(1999, 2024)]\n",
    "PREPROCESSOR = preprocessing.NFLPreprocessing(FILE_LIST)\n",
    "TARGET_NAME = 'yards_gained'\n",
    "PRED_SAVE_NAME = 'predicted yards_gained'\n",
    "RANDOM_STATE = 42\n",
    "LABEL_PASS = 'Pass'\n",
    "LABEL_RUN = 'Run'\n",
    "\n",
    "# global variables to save files\n",
    "model_counter = 0\n",
    "plot_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(df: pd.DataFrame, data_fraction: float):\n",
    "    \"\"\"\n",
    "    Sample a fraction of the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - data_fraction (float): Fraction of the DataFrame to sample, should be between 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A sampled DataFrame.\n",
    "\n",
    "    Example:\n",
    "    sampled_df = sample_dataframe(df, 0.2)\n",
    "    \"\"\"\n",
    "    # set fraction between 0 and 1 (e.g. 0.05 -> 5% df)\n",
    "    df_sampled = df.sample(frac=data_fraction, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Reset the index if needed\n",
    "    df_sampled = df_sampled.reset_index(drop=True)\n",
    "\n",
    "    return df_sampled\n",
    "\n",
    "def split_feature_target(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Split the input DataFrame into features and target.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two DataFrames - features and target.\n",
    "\n",
    "    Example:\n",
    "    features, target = split_feature_target(df)\n",
    "    \"\"\"\n",
    "    features = df.drop(TARGET_NAME, axis=1)\n",
    "    target = df[TARGET_NAME]\n",
    "\n",
    "    return features, target\n",
    "\n",
    "def plot_predicts(y_test, predictions, label: str):\n",
    "    \"\"\"\n",
    "    Plot actual vs. predicted values and display regression metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_test (array-like): True values.\n",
    "    - predictions (array-like): Predicted values.\n",
    "    - label (str): Label for the plot.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    plot_predicts(y_true, y_pred, \"Linear Regression\")\n",
    "    \"\"\"\n",
    "    # print metrics\n",
    "    pass_mse = mean_squared_error(y_test, predictions)\n",
    "    pass_rmse = mean_squared_error(y_test, predictions, squared = False)\n",
    "    pass_msa = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    # Visualize predictions for passes\n",
    "    plt.scatter(y_test, predictions)\n",
    "    plt.title(label + ' Model: True vs Predicted Yards')\n",
    "    plt.xlabel('True Yards')\n",
    "    plt.ylabel('Predicted Yards')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Mean Squared Error: {pass_mse}\")\n",
    "    print(f\"Mean Absolute Error: {pass_msa}\")\n",
    "    print(f\"Root Mean Squared Error: {pass_rmse}\")\n",
    "\n",
    "def plot_decision_tree(pipeline, label: str, target_tree: int = 0):\n",
    "    \"\"\"\n",
    "    Plot a decision tree from a pipeline.\n",
    "    \n",
    "    Parameters:\n",
    "    - pipeline: A pipeline containing a decision tree regressor.\n",
    "    - label (str): Label for the plot.\n",
    "    - target_tree (int): Index of the tree to plot.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    plot_decision_tree(pipeline, \"Random Forest\")\n",
    "    \"\"\"\n",
    "    global plot_counter\n",
    "    fileName = f'./results/plot_{plot_counter}_{label}_rf'\n",
    "    # Export the decision tree as a dot file\n",
    "    export_graphviz(pipeline.named_steps['regressor'].estimators_[target_tree], out_file=f'{fileName}.dot', \n",
    "                    feature_names=PREPROCESSOR.get_prepro_feature_names_from_pipeline(),\n",
    "                    rounded=True, proportion=False, \n",
    "                    precision=2, filled=True)\n",
    "\n",
    "    # Convert the dot file to png using Graphviz (make sure Graphviz is installed)\n",
    "    call(['dot', '-Tpng', f'{fileName}.dot', '-o', f'{fileName}.png', '-Gdpi=600'])\n",
    "\n",
    "    plot_counter = plot_counter + 1\n",
    "\n",
    "    display(Image(filename=f'{fileName}.png'))\n",
    "\n",
    "def plot_decision_tree_xgb(pipeline, label: str, target_tree: int=0):\n",
    "    \"\"\"\n",
    "    Plot an XGBoost decision tree from a pipeline.\n",
    "    \n",
    "    Parameters:\n",
    "    - pipeline: A pipeline containing an XGBoost regressor.\n",
    "    - label (str): Label for the plot.\n",
    "    - target_tree (int): Index of the tree to plot.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    plot_decision_tree_xgb(pipeline, \"XGBoost\")\n",
    "    \"\"\"\n",
    "    global plot_counter\n",
    "    fileName = f'./results/plot_{plot_counter}_{label}_xgb'\n",
    "\n",
    "    xgb.plot_tree(pipeline.named_steps['regressor'], num_trees=target_tree, fmap='featureMap.txt')\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(15, 10)\n",
    "    fig.canvas.manager.set_window_title('Decision Tree for ' + label + ' Model')\n",
    "    fig.savefig(f'{fileName}.png')\n",
    "    \n",
    "    plot_counter = plot_counter + 1\n",
    "\n",
    "    Image(filename=f'{fileName}.png')\n",
    "\n",
    "def plot_train_val_loss(training_losses: list, validation_losses: list, label: str):\n",
    "    \"\"\"\n",
    "    Plot training and validation loss for a neural network.\n",
    "\n",
    "    Parameters:\n",
    "    - training_losses (list): Training loss values.\n",
    "    - validation_losses (list): Validation loss values.\n",
    "    - label (str): Label for the plot.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    plot_train_val_loss(train_loss, val_loss, \"Neural Network\")\n",
    "    \"\"\"\n",
    "    global plot_counter\n",
    "    fileName = f'./results/plot_{plot_counter}_{label}_ann'\n",
    "    # Plot the training and validation loss\n",
    "    plt.plot(training_losses, label='Training Loss')\n",
    "    plt.plot(validation_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Neural Network Training and Validation Loss - ' + label)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{fileName}.png')\n",
    "    plt.show()\n",
    "    plot_counter = plot_counter + 1\n",
    "\n",
    "def plot_feature_importances(pipeline, label: str, show_top_n: int=10):\n",
    "    \"\"\"\n",
    "    Plot feature importances from a pipeline.\n",
    "    \n",
    "    Parameters:\n",
    "    - pipeline: A pipeline containing a model with feature importances.\n",
    "    - label (str): Label for the plot.\n",
    "    - show_top_n (int): Number of top features to display.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    plot_feature_importances(pipeline, \"Random Forest\")\n",
    "    \"\"\"\n",
    "    global plot_counter\n",
    "    fileName = f'./results/plot_{plot_counter}_{label}_feature_importance'\n",
    "    # Get feature importances\n",
    "    feature_importances = pipeline.named_steps['regressor'].feature_importances_\n",
    "\n",
    "    # Get the feature names after preprocessing\n",
    "    columns = PREPROCESSOR.get_prepro_feature_names_from_pipeline()\n",
    "\n",
    "    # Create a DataFrame to display feature importances\n",
    "    feature_importance_df = pd.DataFrame({'Feature': columns, 'Importance': feature_importances})\n",
    "\n",
    "    # Sort the DataFrame by importance in descending order\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Plot the feature importances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance_df['Feature'][:show_top_n], feature_importance_df['Importance'][:show_top_n])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top {show_top_n} Feature Importances - {label}')\n",
    "    plt.savefig(f'{fileName}.png')\n",
    "    plt.show()\n",
    "    plot_counter = plot_counter + 1\n",
    "\n",
    "def plot_coef(pipeline, label: str):\n",
    "    \"\"\"\n",
    "    Plot coefficients from a linear regression pipeline.\n",
    "    Parameters:\n",
    "    - pipeline: A pipeline containing a linear regression model.\n",
    "    - label (str): Label for the plot.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    plot_coef(pipeline, \"Linear Regression\")\n",
    "    \"\"\"\n",
    "    global plot_counter\n",
    "    fileName = f'./results/plot_{plot_counter}_{label}_feature_importance'\n",
    "    coefs = pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "    # Get the feature names after preprocessing\n",
    "    columns = PREPROCESSOR.get_prepro_feature_names_from_pipeline()\n",
    "\n",
    "    coef = pd.DataFrame(coefs, columns=[\"Coefficients\"], index=columns)\n",
    "    coef.plot(kind=\"barh\", figsize=(9, 7))\n",
    "    plt.savefig(f'{fileName}.png')\n",
    "    plt.show()\n",
    "    plot_counter = plot_counter + 1\n",
    "\n",
    "def estimate_model_from_excel(path: str):\n",
    "    \"\"\"\n",
    "    Load data from an Excel file, estimate model predictions, and plot the results.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    estimate_model_from_excel(\"path/to/excel/file.xlsx\")\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(path)\n",
    "\n",
    "    # drop na-rows if for some datarows no prediction has been made\n",
    "    df = df.dropna()\n",
    "    label = path.split('_')[2]\n",
    "\n",
    "    target = df[TARGET_NAME]\n",
    "    predictions = df[PRED_SAVE_NAME]\n",
    "\n",
    "    plot_predicts(target, predictions, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(pipeline, df: pd.DataFrame, data_fraction: float = None, label = None):\n",
    "    \"\"\"\n",
    "    Test a machine learning model using a specified pipeline.\n",
    "    Parameters:\n",
    "    - pipeline: The machine learning model pipeline.\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - data_fraction (float, optional): Fraction of the DataFrame to use for testing. Default is None.\n",
    "    - label (str, optional): Label for the plot and saved model file. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing true values and predicted values.\n",
    "\n",
    "    Example:\n",
    "    y_true, y_pred = test_model(pipeline, df, data_fraction=0.2, label=\"Random Forest\")\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "    if(data_fraction and data_fraction < 1.0):\n",
    "        data = get_sample(data, data_fraction)\n",
    "    \n",
    "    features, target = split_feature_target(data)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions = pipeline.predict(X_test)\n",
    "\n",
    "    plot_predicts(y_test, predictions, label if label else '')\n",
    "    save_model(features, target, predictions, label, title_appendix=f'normal_{data_fraction*100}%_of_data')\n",
    "\n",
    "    return y_test, predictions\n",
    "\n",
    "def test_model_k_fold(df: pd.DataFrame, pipeline, label: str, k_folds: int=3, data_fraction: float = 1.0):\n",
    "    \"\"\"\n",
    "    Test a machine learning model using k-fold cross-validation.\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - pipeline: The machine learning model pipeline.\n",
    "    - label (str): Label for the plot and saved model file.\n",
    "    - k_folds (int, optional): Number of folds for cross-validation. Default is 3.\n",
    "    - data_fraction (float, optional): Fraction of the DataFrame to use for testing. Default is 1.0.\n",
    "\n",
    "    Returns:\n",
    "    array-like: Predicted values from cross-validation.\n",
    "\n",
    "    Example:\n",
    "    cv_predictions = test_model_k_fold(df, pipeline, \"Random Forest\", k_folds=5, data_fraction=0.8)\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "    if(data_fraction and data_fraction < 1.0):\n",
    "        data = get_sample(df, data_fraction)\n",
    "    \n",
    "    features, target = split_feature_target(data)\n",
    "\n",
    "    cv_predictions = cross_val_predict(pipeline, features, target, cv=k_folds)\n",
    "    \n",
    "    plot_predicts(target, cv_predictions, label)\n",
    "    save_model(features, target, cv_predictions, label, title_appendix=f'{k_folds}_folds_{data_fraction*100}%_of_data')\n",
    "    return cv_predictions\n",
    "\n",
    "def estimate_hyperparams(df: pd.DataFrame, pipeline, scoring: str, label: str, k_folds: int=3, parameters: dict={}, data_fraction: float = 1.0):\n",
    "    \"\"\"\n",
    "    Estimate hyperparameters using grid search and cross-validation.\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - pipeline: The machine learning model pipeline.\n",
    "    - scoring (str): Scoring metric for grid search.\n",
    "    - label (str): Label for saving results.\n",
    "    - k_folds (int, optional): Number of folds for cross-validation. Default is 3.\n",
    "    - parameters (dict, optional): Hyperparameter grid for grid search. Default is an empty dictionary.\n",
    "    - data_fraction (float, optional): Fraction of the DataFrame to use for testing. Default is 1.0.\n",
    "\n",
    "    Returns:\n",
    "    GridSearchCV: Grid search estimator.\n",
    "\n",
    "    Example:\n",
    "    grid_search_estimator = estimate_hyperparams(df, pipeline, \"neg_mean_squared_error\", \"Random Forest\", k_folds=5, parameters={'n_estimators': [50, 100, 200]})\n",
    "    \"\"\"\n",
    "    global model_counter\n",
    "    data = df.copy()\n",
    "    if(data_fraction and data_fraction < 1.0):\n",
    "        data = get_sample(df, data_fraction)\n",
    "\n",
    "    features, target = split_feature_target(data)\n",
    "    \n",
    "    # create the grid search instance\n",
    "    grid_search_estimator = GridSearchCV(pipeline, parameters, scoring=scoring, cv=k_folds, return_train_score=False, n_jobs=1)\n",
    "\n",
    "    # run the grid search\n",
    "    grid_search_estimator.fit(features, target)\n",
    "    \n",
    "    cv_results_df = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "    cv_results_df.to_excel(f'./results/model_{model_counter}_{label}_nestedCV_{data_fraction*100}%_of_data.xlsx')\n",
    "    model_counter = model_counter + 1\n",
    "    display(grid_search_estimator.best_params_)\n",
    "    display(cv_results_df)\n",
    "\n",
    "    return grid_search_estimator\n",
    "\n",
    "def generate_param_combinations(parameters: dict):\n",
    "    \"\"\"\n",
    "    Generate combinations of hyperparameters for grid search.\n",
    "    Parameters:\n",
    "    - parameters (dict): Hyperparameter grid.\n",
    "\n",
    "    Returns:\n",
    "    list: List of dictionaries representing hyperparameter combinations.\n",
    "\n",
    "    Example:\n",
    "    param_combinations = generate_param_combinations({'n_estimators': [50, 100], 'max_depth': [None, 10]})\n",
    "    \"\"\"\n",
    "    return list(ParameterGrid(parameters))\n",
    "\n",
    "def save_model(features: pd.DataFrame, target: pd.Series, predictions, label: str, title_appendix: str = ''):\n",
    "    \"\"\"\n",
    "    Save model results (features, target, predictions) to an Excel file.\n",
    "\n",
    "    Parameters:\n",
    "    - features (pd.DataFrame): Features used in the model.\n",
    "    - target (pd.Series): Target variable.\n",
    "    - predictions (array-like): Model predictions.\n",
    "    - label (str): Label for the saved file.\n",
    "    - title_appendix (str, optional): Appendix to the title for differentiation. Default is an empty string.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    save_model(features, target, predictions, \"Random Forest\", title_appendix=\"normal_20%_of_data\")\n",
    "    \"\"\"\n",
    "    global model_counter\n",
    "\n",
    "    predictions_df = pd.DataFrame({'predicted yards_gained': predictions})\n",
    "    save_model = pd.concat([features, target, predictions_df], axis=1)\n",
    "\n",
    "    if (title_appendix != ''):\n",
    "        title_appendix = '_'+title_appendix\n",
    "    save_model.to_excel(f'./results/model_{model_counter}_{label}{title_appendix}.xlsx')\n",
    "\n",
    "    # increase counter for files\n",
    "    model_counter = model_counter + 1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MLP Regressor Class - with history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPWithHistory(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mlp_params=None):\n",
    "        self.mlp_params = mlp_params\n",
    "        self.training_losses = []\n",
    "        self.validation_losses = []\n",
    "        self.mlp_regressor = MLPRegressor(**(self.mlp_params or {}))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, X_val, y, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        for epoch in range(self.mlp_regressor.max_iter):\n",
    "            self.mlp_regressor.partial_fit(X, y)\n",
    "\n",
    "            # Calculate training loss\n",
    "            y_train_pred = self.mlp_regressor.predict(X)\n",
    "            training_loss = mean_squared_error(y, y_train_pred)\n",
    "            self.training_losses.append(training_loss)\n",
    "\n",
    "            # Calculate validation loss\n",
    "            y_val_pred = self.mlp_regressor.predict(X_val)\n",
    "            validation_loss = mean_squared_error(y_val, y_val_pred)\n",
    "            self.validation_losses.append(validation_loss)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.mlp_regressor.predict(X)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"mlp_params\": self.mlp_params}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.mlp_params = params[\"mlp_params\"]\n",
    "        self.mlp_regressor.set_params(**self.mlp_params)\n",
    "        return self\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return -mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(340092, 24)\n",
      "(444089, 24)\n"
     ]
    }
   ],
   "source": [
    "# fetching the selected dataset from the preprocessor class\n",
    "run_df = PREPROCESSOR.run_df\n",
    "pass_df = PREPROCESSOR.pass_df\n",
    "\n",
    "# split data into feature and target\n",
    "run_features, run_target = split_feature_target(run_df)\n",
    "pass_features, pass_target = split_feature_target(pass_df)\n",
    "\n",
    "# print initial information\n",
    "print(run_features.shape)\n",
    "print(pass_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Dataset Baseline Metrics:\n",
      "Mean Squared Error (MSE) baseline: 41.27116486127283\n",
      "Root Mean Squared Error (RMSE) baseline: 6.424263760250884\n",
      "Mean Absolute Error (MAE) baseline: 3.6414587817414112\n",
      "Pass Dataset Baseline Metrics:\n",
      "Mean Squared Error (MSE) baseline: 109.61465156759118\n",
      "Root Mean Squared Error (RMSE) baseline: 10.469701598784523\n",
      "Mean Absolute Error (MAE) baseline: 6.845260747282639\n"
     ]
    }
   ],
   "source": [
    "# calculating median of selected data\n",
    "median_run = np.median(run_target)\n",
    "median_pass = np.median(pass_target)\n",
    "\n",
    "# estimating metrics\n",
    "mse_run_baseline = mean_squared_error(run_target, np.full_like(run_target, median_run))\n",
    "mse_pass_baseline = mean_squared_error(pass_target, np.full_like(pass_target, median_pass))\n",
    "\n",
    "rmse_run_baseline = np.sqrt(mse_run_baseline)\n",
    "rmse_pass_baseline = np.sqrt(mse_pass_baseline)\n",
    "\n",
    "mae_run_baseline = mean_absolute_error(run_target, np.full_like(run_target, median_run))\n",
    "mae_pass_baseline = mean_absolute_error(pass_target, np.full_like(pass_target, median_pass))\n",
    "\n",
    "# print metrics\n",
    "print(\"Run Dataset Baseline Metrics:\")\n",
    "print(\"Mean Squared Error (MSE) baseline:\", mse_run_baseline)\n",
    "print(\"Root Mean Squared Error (RMSE) baseline:\", rmse_run_baseline)\n",
    "print(\"Mean Absolute Error (MAE) baseline:\", mae_run_baseline)\n",
    "\n",
    "print(\"Pass Dataset Baseline Metrics:\")\n",
    "print(\"Mean Squared Error (MSE) baseline:\", mse_pass_baseline)\n",
    "print(\"Root Mean Squared Error (RMSE) baseline:\", rmse_pass_baseline)\n",
    "print(\"Mean Absolute Error (MAE) baseline:\", mae_pass_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipelines from preprocessing script\n",
    "pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_y_test, run_predictions = test_model(pipeline, run_df, 1.0, label=LABEL_RUN)\n",
    "plot_coef(pipeline, LABEL_RUN)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_y_test, pass_predictions = test_model(pipeline, pass_df, 1.0, label=LABEL_PASS)\n",
    "plot_coef(pipeline, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning for linear regression\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "\n",
    "parameters = {\n",
    "    'regressor__fit_intercept': [True, False],\n",
    "    'regressor__random_state': [RANDOM_STATE],\n",
    "    'outlier_remover__kw_args': [\n",
    "        {\n",
    "            'save_stats': False,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "run_grid_search = estimate_hyperparams(run_df, pipeline, 'neg_root_mean_squared_error', LABEL_RUN, parameters=parameters, data_fraction=1.0)\n",
    "pass_grid_search = estimate_hyperparams(pass_df, pipeline, 'neg_root_mean_squared_error', LABEL_PASS, parameters=parameters, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_params = {\n",
    "    'outlier_remover__kw_args': {\n",
    "        'save_stats': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# make pipelines from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "\n",
    "run_params = run_grid_search.best_params_\n",
    "run_params.update(logging_params)\n",
    "\n",
    "pass_params = pass_grid_search.best_params_\n",
    "pass_params.update(logging_params)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_pipeline = run_pipeline.set_params(**run_params)\n",
    "run_predictions = test_model_k_fold(run_df, run_pipeline, LABEL_RUN, data_fraction=1.0)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_pipeline = pass_pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model_k_fold(pass_df, pass_pipeline, LABEL_PASS, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipelines from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "\n",
    "run_params = run_grid_search.best_params_\n",
    "pass_params = pass_grid_search.best_params_\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_pipeline = run_pipeline.set_params(**run_params)\n",
    "run_predictions = test_model(run_pipeline, run_df, label = LABEL_RUN, data_fraction=1.0)\n",
    "\n",
    "plot_coef(run_pipeline, LABEL_RUN)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_pipeline = pass_pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model(pass_pipeline, pass_df, label = LABEL_PASS, data_fraction=1.0)\n",
    "\n",
    "plot_coef(pass_pipeline, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipelines from preprocessing script\n",
    "pipeline = PREPROCESSOR.make_preprocessing_pipeline(Ridge())\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_y_test, run_predictions = test_model(pipeline, run_df, 1.0, label=LABEL_RUN)\n",
    "plot_coef(pipeline, LABEL_RUN)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_y_test, pass_predictions = test_model(pipeline, pass_df, 1.0, label=LABEL_PASS)\n",
    "plot_coef(pipeline, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning for linear regression\n",
    "\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Ridge())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Ridge())\n",
    "\n",
    "parameters = {\n",
    "    'regressor__alpha': [x / 10.0 for x in range(6, 15, 2)],\n",
    "    'regressor__fit_intercept': [True, False],\n",
    "    'regressor__max_iter': [1000, 7500, 15000],\n",
    "    'regressor__tol': [0.0001, 0.0005, 0.001],\n",
    "#    'regressor__solver': ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs'],\n",
    "    'regressor__random_state': [RANDOM_STATE],\n",
    "    'outlier_remover__kw_args': [\n",
    "        {\n",
    "            'save_stats': False,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "run_grid_search = estimate_hyperparams(run_df, pipeline, 'neg_root_mean_squared_error', LABEL_RUN, parameters=parameters, data_fraction=1.0)\n",
    "pass_grid_search = estimate_hyperparams(pass_df, pipeline, 'neg_root_mean_squared_error', LABEL_PASS, parameters=parameters, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning for linear regression\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Ridge())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Ridge())\n",
    "\n",
    "# same again for run and pass, as both have the same best params\n",
    "parameters = {\n",
    "    'regressor__alpha': [x / 10.0 for x in range(12, 21, 1)],\n",
    "    'regressor__fit_intercept': [True, False],\n",
    "    'regressor__max_iter': [800, 900, 1000, 1100, 1200],\n",
    "    'regressor__tol': [0.00008, 0.00009, 0.0001, 0.00011, 0.00012],\n",
    "    'regressor__random_state': [RANDOM_STATE],\n",
    "    'outlier_remover__kw_args': [\n",
    "        {\n",
    "            'save_stats': False,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "run_grid_search = estimate_hyperparams(run_df, pipeline, 'neg_root_mean_squared_error', LABEL_RUN, parameters=parameters, data_fraction=1.0)\n",
    "pass_grid_search = estimate_hyperparams(pass_df, pipeline, 'neg_root_mean_squared_error', LABEL_PASS, parameters=parameters, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_params = {\n",
    "    'outlier_remover__kw_args': {\n",
    "        'save_stats': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# make pipelines from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Ridge())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Ridge())\n",
    "\n",
    "run_params = run_grid_search.best_params_\n",
    "run_params.update(logging_params)\n",
    "\n",
    "pass_params = pass_grid_search.best_params_\n",
    "pass_params.update(logging_params)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_pipeline = run_pipeline.set_params(**run_params)\n",
    "run_predictions = test_model_k_fold(run_df, run_pipeline, LABEL_RUN, data_fraction=1.0)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_pipeline = pass_pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model_k_fold(pass_df, pass_pipeline, LABEL_PASS, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipelines from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Ridge())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Ridge())\n",
    "\n",
    "run_params = run_grid_search.best_params_\n",
    "pass_params = pass_grid_search.best_params_\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_pipeline = run_pipeline.set_params(**run_params)\n",
    "run_predictions = test_model(run_pipeline, run_df, label = LABEL_RUN, data_fraction=1.0)\n",
    "\n",
    "plot_coef(run_pipeline, LABEL_RUN)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_pipeline = pass_pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model(pass_pipeline, pass_df, label = LABEL_PASS, data_fraction=1.0)\n",
    "\n",
    "plot_coef(pass_pipeline, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipelines from preprocessing script\n",
    "pipeline = PREPROCESSOR.make_preprocessing_pipeline(Lasso())\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_y_test, run_predictions = test_model(pipeline, run_df, 1.0, label=LABEL_RUN)\n",
    "plot_coef(pipeline, LABEL_RUN)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_y_test, pass_predictions = test_model(pipeline, pass_df, 1.0, label=LABEL_PASS)\n",
    "plot_coef(pipeline, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning for Lasso regression\n",
    "\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Lasso())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Lasso())\n",
    "\n",
    "parameters = {\n",
    "    'regressor__alpha': [x / 10.0 for x in range(6, 15, 2)],\n",
    "    'regressor__fit_intercept': [True, False],\n",
    "    'regressor__max_iter': [800, 900, 1000, 1100, 1200],\n",
    "    'regressor__tol': [0.00005, 0.0001, 0.00015],\n",
    "    'regressor__warm_start': [True, False],\n",
    "    'regressor__random_state': [RANDOM_STATE],\n",
    "    'regressor__selection': ['cyclic', 'random'],\n",
    "    'outlier_remover__kw_args': [\n",
    "        {\n",
    "            'save_stats': False,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "run_grid_search = estimate_hyperparams(run_df, pipeline, 'neg_root_mean_squared_error', LABEL_RUN, parameters=parameters, data_fraction=1.0)\n",
    "pass_grid_search = estimate_hyperparams(pass_df, pipeline, 'neg_root_mean_squared_error', LABEL_PASS, parameters=parameters, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_params = {\n",
    "    'outlier_remover__kw_args': {\n",
    "        'save_stats': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# make pipelines from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Lasso())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Lasso())\n",
    "\n",
    "run_params = run_grid_search.best_params_\n",
    "run_params.update(logging_params)\n",
    "\n",
    "pass_params = pass_grid_search.best_params_\n",
    "pass_params.update(logging_params)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_pipeline = run_pipeline.set_params(**run_params)\n",
    "run_predictions = test_model_k_fold(run_df, run_pipeline, LABEL_RUN, data_fraction=1.0)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_pipeline = pass_pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model_k_fold(pass_df, pass_pipeline, LABEL_PASS, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipelines from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Lasso())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(Lasso())\n",
    "\n",
    "run_params = run_grid_search.best_params_\n",
    "pass_params = pass_grid_search.best_params_\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_pipeline = run_pipeline.set_params(**run_params)\n",
    "run_predictions = test_model(run_pipeline, run_df, label = LABEL_RUN, data_fraction=1.0)\n",
    "\n",
    "plot_coef(run_pipeline, LABEL_RUN)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_pipeline = pass_pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model(pass_pipeline, pass_df, label = LABEL_PASS, data_fraction=1.0)\n",
    "\n",
    "plot_coef(pass_pipeline, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipelines from preprocessing script\n",
    "pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_y_test, run_predictions = test_model(pipeline, run_df, 1.0, label=LABEL_RUN)\n",
    "plot_coef(pipeline, LABEL_RUN)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_y_test, pass_predictions = test_model(pipeline, pass_df, 1.0, label=LABEL_PASS)\n",
    "plot_coef(pipeline, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning for linear regression\n",
    "\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "\n",
    "parameters = {\n",
    "    'regressor__fit_intercept': [True, False],\n",
    "    'outlier_remover__kw_args': [\n",
    "        {\n",
    "            'save_stats': False,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "run_grid_search = estimate_hyperparams(run_df, pipeline, 'neg_root_mean_squared_error', LABEL_RUN, parameters=parameters, data_fraction=1.0)\n",
    "pass_grid_search = estimate_hyperparams(pass_df, pipeline, 'neg_root_mean_squared_error', LABEL_PASS, parameters=parameters, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_params = {\n",
    "    'outlier_remover__kw_args': {\n",
    "        'save_stats': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# make pipelines from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "\n",
    "run_params = run_grid_search.best_params_\n",
    "run_params.update(logging_params)\n",
    "\n",
    "pass_params = pass_grid_search.best_params_\n",
    "pass_params.update(logging_params)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_pipeline = run_pipeline.set_params(**run_params)\n",
    "run_predictions = test_model_k_fold(run_df, run_pipeline, LABEL_RUN, data_fraction=1.0)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_pipeline = pass_pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model_k_fold(pass_df, pass_pipeline, LABEL_PASS, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipelines from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(LinearRegression())\n",
    "\n",
    "run_params = run_grid_search.best_params_\n",
    "pass_params = pass_grid_search.best_params_\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_pipeline = run_pipeline.set_params(**run_params)\n",
    "run_predictions = test_model(run_pipeline, run_df, label = LABEL_RUN, data_fraction=1.0)\n",
    "\n",
    "plot_coef(run_pipeline, LABEL_RUN)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_pipeline = pass_pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model(pass_pipeline, pass_df, label = LABEL_PASS, data_fraction=1.0)\n",
    "\n",
    "plot_coef(pass_pipeline, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic model\n",
    "\n",
    "# make pipelines from preprocessing script\n",
    "poly_pipeline = Pipeline([('polynomialfeatures', PolynomialFeatures()), ('linear_regression', LinearRegression())])\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(poly_pipeline)\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(poly_pipeline)\n",
    "\n",
    "# test model and save predictions\n",
    "run_y_test, run_predictions = test_model(run_pipeline, run_df, 0.25, label=LABEL_RUN)\n",
    "pass_y_test, pass_predictions = test_model(pass_pipeline, run_df, 0.25, label=LABEL_PASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new pipeliness from preprocessing script\n",
    "poly_pipeline = Pipeline([('polynomialfeatures', PolynomialFeatures()), ('linear_regression', LinearRegression())])\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(poly_pipeline)\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(poly_pipeline)\n",
    "\n",
    "parameters = {\n",
    "    'regressor__polynomialfeatures__degree': list(range(2,5)) + [(x, x) for x in range(2,5)],\n",
    "    'regressor__polynomialfeatures__interaction_only': [True, False],\n",
    "    'regressor__polynomialfeatures__include_bias': [True, False],\n",
    "    'outlier_remover__kw_args': [\n",
    "        {\n",
    "            'save_stats': False,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "run_grid_search = estimate_hyperparams(run_df, run_pipeline, 'neg_root_mean_squared_error', LABEL_RUN, parameters=parameters, data_fraction=0.5)\n",
    "pass_grid_search = estimate_hyperparams(pass_df, pass_pipeline, 'neg_root_mean_squared_error', LABEL_PASS, parameters=parameters, data_fraction=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation with best hyperparameters\n",
    "\n",
    "logging_params = {\n",
    "    'outlier_remover__kw_args': {\n",
    "        'save_stats': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# make new pipeliness from preprocessing script\n",
    "poly_pipeline = Pipeline([('polynomialfeatures', PolynomialFeatures()), ('linear_regression', LinearRegression())])\n",
    "pipeline = PREPROCESSOR.make_preprocessing_pipeline(poly_pipeline)\n",
    "\n",
    "run_params = run_grid_search.best_params_\n",
    "run_params.update(logging_params)\n",
    "\n",
    "pass_params = pass_grid_search.best_params_\n",
    "pass_params.update(logging_params)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_pipeline = pipeline.set_params(**run_params)\n",
    "run_predictions = test_model_k_fold(run_df, run_pipeline, LABEL_RUN, data_fraction=1.0)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_pipeline = pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model_k_fold(pass_df, pass_pipeline, LABEL_PASS, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model\n",
    "\n",
    "# make pipelines\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(KNeighborsRegressor(n_neighbors=3))\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(KNeighborsRegressor(n_neighbors=3))\n",
    "\n",
    "# test model and save predictions\n",
    "run_y_test, run_predictions = test_model(run_pipeline, run_df, 0.2)\n",
    "pass_y_test, pass_predictions = test_model(pass_pipeline, run_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating hyperparameters\n",
    "parameters = {\n",
    "    'regressor__n_neighbors': range(5,10),\n",
    "    'outlier_remover__kw_args': [\n",
    "        {\n",
    "            'strict_columns': ['yardline_100', 'ydstogo', 'score_differential', 'td_prob', 'drive_play_count', 'drive_start_yard_line', 'spread_line', 'total_line', 'overall'],\n",
    "        },\n",
    "        {\n",
    "            'strict_columns': [],\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# make new pipeliness from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(KNeighborsRegressor())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(KNeighborsRegressor())\n",
    "\n",
    "# run grid search for run and pass with the whole dataset and the hyperparameters specified above\n",
    "run_grid_search = estimate_hyperparams(run_df, run_pipeline, 'neg_root_mean_squared_error', 'KNN_RUN', k_folds=3, parameters=parameters, data_fraction=1.0)\n",
    "pass_grid_search = estimate_hyperparams(pass_df, pass_pipeline, 'neg_root_mean_squared_error', 'KNN_RUN', k_folds=3, parameters=parameters, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation with best hyperparameters\n",
    "\n",
    "# make new pipeliness from preprocessing script\n",
    "pipeline = PREPROCESSOR.make_preprocessing_pipeline(KNeighborsRegressor())\n",
    "\n",
    "# get the best parameters from the hyperparameter tuning\n",
    "run_params = run_grid_search.best_params_\n",
    "pass_params = pass_grid_search.best_params_\n",
    "\n",
    "# set params, test model and save predictions for run\n",
    "pipeline = pipeline.set_params(**run_params)\n",
    "run_predictions = test_model_k_fold(run_df, pipeline, LABEL_RUN, data_fraction=1.0)\n",
    "\n",
    "# set params, test model and save predictions for pass\n",
    "pipeline = pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model_k_fold(pass_df, pipeline, LABEL_PASS, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model\n",
    "run_params = {\n",
    "    'outlier_remover__kw_args': {\n",
    "        'save_stats': False,\n",
    "    }\n",
    "}\n",
    "\n",
    "pass_params = {\n",
    "    'outlier_remover__kw_args': {\n",
    "        'save_stats': False,\n",
    "    }\n",
    "}\n",
    "\n",
    "# make pipelines\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(RandomForestRegressor(n_estimators=100, random_state=42, max_depth=5))\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(RandomForestRegressor(n_estimators=100, random_state=42, max_depth=5))\n",
    "\n",
    "run_pipeline.set_params(**run_params)\n",
    "pass_pipeline.set_params(**pass_params)\n",
    "\n",
    "# test model and save predictions\n",
    "run_y_test, run_predictions = test_model(run_pipeline, run_df, 0.25, label=LABEL_RUN)\n",
    "plot_feature_importances(run_pipeline, LABEL_RUN)\n",
    "\n",
    "pass_y_test, pass_predictions = test_model(pass_pipeline, pass_df, 0.25, label=LABEL_PASS)\n",
    "plot_feature_importances(pass_pipeline, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating hyperparameters\n",
    "\n",
    "# make new pipeliness from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(RandomForestRegressor())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(RandomForestRegressor())\n",
    "\n",
    "parameters = {\n",
    "    'regressor__max_depth': [5, 10, 20],\n",
    "    'regressor__n_estimators': [20, 50],\n",
    "    'regressor__min_samples_split': [50, 100],\n",
    "    'regressor__min_samples_leaf': [10, 20],\n",
    "    'regressor__max_features': ['sqrt', 'log2', 1, None],\n",
    "    'regressor__random_state': [RANDOM_STATE],\n",
    "    'outlier_remover__kw_args': [\n",
    "        {\n",
    "            'save_stats': False,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "run_grid_search = estimate_hyperparams(run_df, run_pipeline, 'neg_root_mean_squared_error', LABEL_RUN, k_folds=3, parameters=parameters, data_fraction=1.0)\n",
    "pass_grid_search = estimate_hyperparams(pass_df, pass_pipeline, 'neg_root_mean_squared_error', LABEL_PASS, k_folds=3, parameters=parameters, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further estimating\n",
    "\n",
    "# make new pipeliness from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(RandomForestRegressor())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(RandomForestRegressor())\n",
    "\n",
    "# representing the best params from last round / the area next to it\n",
    "run_parameters = {\n",
    "    'regressor__max_depth': range(8, 13),\n",
    "    'regressor__n_estimators': [45, 50, 55],\n",
    "    'regressor__min_samples_split': [40, 50, 60],\n",
    "    'regressor__min_samples_leaf': [20],\n",
    "    'regressor__max_features': [None],\n",
    "    'regressor__random_state': [RANDOM_STATE],\n",
    "    'outlier_remover__kw_args': [\n",
    "        {\n",
    "            'save_stats': False,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "pass_parameters = {\n",
    "    'regressor__max_depth': range(8, 13),\n",
    "    'regressor__n_estimators': [45, 50, 55],\n",
    "    'regressor__min_samples_split': [90, 100, 110],\n",
    "    'regressor__min_samples_leaf': [10],\n",
    "    'regressor__max_features': ['sqrt'],\n",
    "    'regressor__random_state': [RANDOM_STATE],\n",
    "    'outlier_remover__kw_args': [\n",
    "        {\n",
    "            'save_stats': False,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "run_grid_search = estimate_hyperparams(run_df, run_pipeline, 'neg_root_mean_squared_error', LABEL_RUN, k_folds=3, parameters=run_parameters, data_fraction=1.0)\n",
    "pass_grid_search = estimate_hyperparams(pass_df, pass_pipeline, 'neg_root_mean_squared_error', LABEL_PASS, k_folds=3, parameters=pass_parameters, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation with best hyperparameters\n",
    "\n",
    "logging_params = {\n",
    "    'outlier_remover__kw_args': {\n",
    "        'save_stats': True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# make new pipeliness from preprocessing script\n",
    "pipeline = PREPROCESSOR.make_preprocessing_pipeline(RandomForestRegressor())\n",
    "\n",
    "run_params = run_grid_search.best_params_\n",
    "run_params.update(logging_params)\n",
    "\n",
    "pass_params = pass_grid_search.best_params_\n",
    "pass_params.update(logging_params)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "run_pipeline = pipeline.set_params(**run_params)\n",
    "run_predictions = test_model_k_fold(run_df, run_pipeline, LABEL_RUN, data_fraction=1.0)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pass_pipeline = pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model_k_fold(pass_df, pass_pipeline, LABEL_PASS, data_fraction=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(run_pipeline, LABEL_RUN)\n",
    "\n",
    "plot_feature_importances(run_pipeline, LABEL_RUN)\n",
    "\n",
    "# Plot the decision tree for passes\n",
    "plot_decision_tree(run_pipeline, LABEL_RUN)\n",
    "\n",
    "# Plot the decision tree for runs\n",
    "plot_decision_tree(pass_pipeline, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model\n",
    "\n",
    "# make pipelines\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(\n",
    "    xgb.XGBRegressor(\n",
    "        learning_rate = 0.022,\n",
    "        n_estimators  = 1000,\n",
    "        max_depth     = 8,\n",
    "        eval_metric='rmsle'\n",
    "                           )\n",
    ")\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(\n",
    "    xgb.XGBRegressor(\n",
    "        learning_rate = 0.015,\n",
    "        n_estimators  = 1000,\n",
    "        max_depth     = 8,\n",
    "        eval_metric='rmsle'\n",
    "        )\n",
    ")\n",
    "\n",
    "# test model and save predictions\n",
    "run_y_test, run_predictions = test_model(run_pipeline, run_df, 0.05)\n",
    "pass_y_test, pass_predictions = test_model(pass_pipeline, run_df, 0.05)\n",
    "\n",
    "# plot the feature importance for run and pass model\n",
    "plot_feature_importances(run_pipeline, LABEL_RUN)\n",
    "plot_feature_importances(pass_pipeline, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating hyperparameters with testing outlier removals\n",
    "\n",
    "# make new pipeliness from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(xgb.XGBRegressor())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(xgb.XGBRegressor())\n",
    "\n",
    "# define the parameters that should be tested\n",
    "parameters = {\n",
    "    \"regressor__max_depth\":    [3, 4, 5],\n",
    "    \"regressor__n_estimators\": [700, 800, 900],\n",
    "    \"regressor__learning_rate\": [0.09, 0.01, 0.011],\n",
    "    \"regressor__gamma\": [0, 5, 10],\n",
    "    'outlier_remover__kw_args': [\n",
    "        {\n",
    "            'strict_columns': ['yardline_100', 'ydstogo', 'score_differential', 'td_prob', 'drive_play_count', 'drive_start_yard_line', 'spread_line', 'total_line', 'overall'],\n",
    "        },\n",
    "        {\n",
    "            'strict_columns': [],\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# run grid search for the defined parameters, first of all with a smaller subset to also test the influence of the outlier removal on the model performance \n",
    "run_grid_search = estimate_hyperparams(run_df, run_pipeline, 'neg_root_mean_squared_error', 'XGB_RUN', k_folds=3, parameters=parameters, data_fraction=0.05)\n",
    "pass_grid_search = estimate_hyperparams(pass_df, pass_pipeline, 'neg_root_mean_squared_error', 'XGB_RUN', k_folds=3, parameters=parameters, data_fraction=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating hyperparameters without testing outlier removals\n",
    "\n",
    "# make new pipeliness from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(xgb.XGBRegressor())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(xgb.XGBRegressor())\n",
    "\n",
    "# define the parameters that should be tested\n",
    "parameters = {\n",
    "    \"regressor__max_depth\":    [3, 6, 9],\n",
    "    \"regressor__n_estimators\": [600, 800, 1000],\n",
    "    \"regressor__learning_rate\": [0.09, 0.01, 0.011],\n",
    "    \"regressor__gamma\": [0, 5, 10]\n",
    "}\n",
    "\n",
    "#run grid search now only with no columns set to strict for the outlier removal as that had given the better results above\n",
    "run_grid_search = estimate_hyperparams(run_df, run_pipeline, 'neg_root_mean_squared_error', 'XGB_RUN', k_folds=3, parameters=parameters, data_fraction=0.25)\n",
    "pass_grid_search = estimate_hyperparams(pass_df, pass_pipeline, 'neg_root_mean_squared_error', 'XGB_RUN', k_folds=3, parameters=parameters, data_fraction=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training & testing the model with the best combination of hyperparameters using a 3 fold cross validation\n",
    "\n",
    "# make new pipeliness from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(xgb.XGBRegressor())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(xgb.XGBRegressor())\n",
    "\n",
    "# extracting the best hyperparameter set from the grid search done previously\n",
    "run_params = run_grid_search.best_params_\n",
    "pass_params = pass_grid_search.best_params_\n",
    "\n",
    "# set params, test model, save predictions and plot the feature importance\n",
    "run_pipeline = run_pipeline.set_params(**run_params)\n",
    "run_predictions = test_model(run_pipeline, run_df, 1.0)\n",
    "plot_feature_importances(run_pipeline, LABEL_RUN)\n",
    "\n",
    "# set params, test model, save predictions and plot the feature importance\n",
    "pass_pipeline = pass_pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model(pass_pipeline, pass_df, 1.0)\n",
    "plot_feature_importances(pass_pipeline, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting more insights into the models\n",
    "\n",
    "# Plot a decision tree for passes\n",
    "plot_decision_tree_xgb(run_pipeline, LABEL_PASS)\n",
    "\n",
    "# Plot a decision tree for runs\n",
    "plot_decision_tree_xgb(pass_pipeline, LABEL_RUN)\n",
    "\n",
    "# plot the feature importance of the pass model by using the weight, gain and the cover \n",
    "xgb.plot_importance(pass_pipeline.named_steps['regressor'], importance_type=\"weight\", fmap='featureMap.txt')\n",
    "xgb.plot_importance(pass_pipeline.named_steps['regressor'], importance_type=\"gain\", fmap='featureMap.txt')\n",
    "xgb.plot_importance(pass_pipeline.named_steps['regressor'], importance_type=\"cover\", fmap='featureMap.txt')\n",
    "\n",
    "# plot the feature importance of the run model by using the weight, gain and the cover \n",
    "xgb.plot_importance(run_pipeline.named_steps['regressor'], importance_type=\"weight\", fmap='featureMap.txt')\n",
    "xgb.plot_importance(run_pipeline.named_steps['regressor'], importance_type=\"gain\", fmap='featureMap.txt')\n",
    "xgb.plot_importance(run_pipeline.named_steps['regressor'], importance_type=\"cover\", fmap='featureMap.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neuronal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic model\n",
    "\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(\n",
    "    MLPWithHistory(\n",
    "        mlp_params={'hidden_layer_sizes': (50,),\n",
    "  'activation': 'relu',\n",
    "  'solver': 'adam',\n",
    "  'max_iter': 100}\n",
    "    )\n",
    ")\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(\n",
    "    MLPWithHistory(\n",
    "        mlp_params={'hidden_layer_sizes': (50,),\n",
    "  'activation': 'relu',\n",
    "  'solver': 'adam',\n",
    "  'max_iter': 100}\n",
    "    )\n",
    ")\n",
    "\n",
    "# estimate run model\n",
    "run_y_test, run_predictions = test_model(run_pipeline, run_df, 0.2)\n",
    "run_mlp = run_pipeline.named_steps['regressor']\n",
    "plot_train_val_loss(run_mlp.training_losses, run_mlp.validation_losses, LABEL_RUN)\n",
    "\n",
    "# estimate pass model\n",
    "pass_y_test, pass_predictions = test_model(pass_pipeline, pass_df, 0.2)\n",
    "pass_mlp = pass_pipeline.named_steps['regressor']\n",
    "plot_train_val_loss(pass_mlp.training_losses, pass_mlp.validation_losses, LABEL_PASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating hyperparameters\n",
    "\n",
    "# make new pipeliness from preprocessing script\n",
    "run_pipeline = PREPROCESSOR.make_preprocessing_pipeline(MLPWithHistory())\n",
    "pass_pipeline = PREPROCESSOR.make_preprocessing_pipeline(MLPWithHistory())\n",
    "\n",
    "parameters = {\n",
    "    'regressor__mlp_params': generate_param_combinations({\n",
    "        'hidden_layer_sizes': [(10,), (50,), (10,5), (20,10)], \n",
    "        'activation': ['relu'], \n",
    "        'solver': ['adam'], \n",
    "        'max_iter': [100] \n",
    "    })\n",
    "}\n",
    "\n",
    "run_grid_search = estimate_hyperparams(run_df, run_pipeline, 'neg_root_mean_squared_error', k_folds=3, parameters=parameters, data_fraction=0.05)\n",
    "pass_grid_search = estimate_hyperparams(pass_df, pass_pipeline, 'neg_root_mean_squared_error', k_folds=3, parameters=parameters, data_fraction=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PREPROCESSOR.make_preprocessing_pipeline(MLPWithHistory())\n",
    "\n",
    "run_params = run_grid_search.best_params_\n",
    "pass_params = pass_grid_search.best_params_\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pipeline = pipeline.set_params(**run_params)\n",
    "run_predictions = test_model_k_fold(run_df, pipeline, LABEL_RUN, data_fraction=1.0)\n",
    "\n",
    "# set params, test model and save predictions\n",
    "pipeline = pipeline.set_params(**pass_params)\n",
    "pass_predictions = test_model_k_fold(pass_df, pipeline, LABEL_PASS, data_fraction=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
